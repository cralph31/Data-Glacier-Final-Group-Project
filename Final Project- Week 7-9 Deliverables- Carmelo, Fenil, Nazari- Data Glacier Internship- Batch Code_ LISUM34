{"metadata": {"kernelspec": {"display_name": "anaconda-2024.02-py310", "language": "python", "name": "conda-env-anaconda-2024.02-py310-py"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.14"}}, "nbformat_minor": 5, "nbformat": 4, "cells": [{"id": "13f1fd0a-ce31-4f41-896b-8610a7b9f928", "cell_type": "markdown", "source": "![title](data_glacier_screenshot_of_assignment.png)", "metadata": {"jupyter": {"source_hidden": true}}}, {"id": "3bcff4a4-fca7-4aba-91d1-b4cb270d8ba8", "cell_type": "markdown", "source": "## Final Project- Bank Marketing Campaign EDA Report- Carmelo R. Casiraro (USA), Fenil Mavani (UK), Nazari (UK), Batch Code: LISUM34- Data Glacier Internship", "metadata": {}}, {"id": "6f6c8901-af89-47a7-810f-c8b753d6ac05", "cell_type": "markdown", "source": "## Problem Statement:\n- ABC Bank wants to sell it's term deposit product to customers and before launching the product they want to develop a model which help them in understanding whether a particular customer will buy their product or not (based on customer's past interaction with bank or other Financial Institution).", "metadata": {"jupyter": {"source_hidden": true}}}, {"id": "129becdc-7f79-4c56-ac02-e76df532266f", "cell_type": "markdown", "source": "# Business Understanding", "metadata": {}}, {"id": "801894f4-ed64-4fb0-ba49-b90822c81300", "cell_type": "markdown", "source": "## Objective\nTo share insights from multiple datasets to develop a model that can help in selling term deposit product.\n\nThe analysis involves:\n- Bank information understanding\n- Data type understanding (whether boolean, string or integer)\n- Looking for any problems in the data and coming up with possible solutions\n- Eliminating any null values, checking for any skewdness or outliers\n- What is the data structure in rows and columns?\n- Raising questions and hypothesis- including charts to understand the data\n- Creating a Exploratory Data Analysis Report to understand and analyze data to create possible recommendations and solutions off charts created\n- What model to develop to help understand the particular customer that will buy the term deposit product or not?", "metadata": {"jp-MarkdownHeadingCollapsed": true, "jupyter": {"source_hidden": true}}}, {"id": "d1e2f2ae-67f9-4c2d-8465-cdd741c08959", "cell_type": "markdown", "source": "## Overall Goal of The Project\n- To generate a EDA report and develop a model with python code to answer questions and make hypotheses about possible solutions and recommendations to sell term deposit to customers.", "metadata": {}}, {"id": "5fa627d3-5ec8-4326-9949-0754ef9db3d5", "cell_type": "markdown", "source": "## Loading Data", "metadata": {}}, {"id": "f522c23a-f9ea-4d84-ba10-3c60a75f3fc5", "cell_type": "code", "source": "import pandas as pd\nfile_path = 'bank-full.csv'\ndata = pd.read_csv(file_path, sep=';')\ndata.head()\n", "metadata": {"trusted": true}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>day</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>58</td>\n      <td>management</td>\n      <td>married</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>2143</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>261</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44</td>\n      <td>technician</td>\n      <td>single</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>29</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>151</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33</td>\n      <td>entrepreneur</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>2</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>76</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>47</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>unknown</td>\n      <td>no</td>\n      <td>1506</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>92</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33</td>\n      <td>unknown</td>\n      <td>single</td>\n      <td>unknown</td>\n      <td>no</td>\n      <td>1</td>\n      <td>no</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>198</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   age           job  marital  education default  balance housing loan  \\\n0   58    management  married   tertiary      no     2143     yes   no   \n1   44    technician   single  secondary      no       29     yes   no   \n2   33  entrepreneur  married  secondary      no        2     yes  yes   \n3   47   blue-collar  married    unknown      no     1506     yes   no   \n4   33       unknown   single    unknown      no        1      no   no   \n\n   contact  day month  duration  campaign  pdays  previous poutcome   y  \n0  unknown    5   may       261         1     -1         0  unknown  no  \n1  unknown    5   may       151         1     -1         0  unknown  no  \n2  unknown    5   may        76         1     -1         0  unknown  no  \n3  unknown    5   may        92         1     -1         0  unknown  no  \n4  unknown    5   may       198         1     -1         0  unknown  no  "}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "execution_count": 8}, {"id": "a0eca145-4030-4176-a683-719f2fb0a73c", "cell_type": "markdown", "source": "## Data Structure\n- Rows: The dataset contains records of customers who were contacted in the marketing campaign.\n- Columns: Each column represents a feature related to the customer's demographics, previous interactions, and campaign details.", "metadata": {}}, {"id": "af094e3c-42a1-4f54-bd09-44c5e107b4c0", "cell_type": "code", "source": "import csv\n\ndef count_rows(file_path):\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        row_count = sum(1 for row in reader)\n    return row_count\n\n# Specify the path to your CSV file\ncsv_file_path = 'bank-full.csv'\n\n# Count the number of rows in the CSV file\nnum_rows = count_rows(csv_file_path)\n\nprint(f\"The CSV file has {num_rows}\u00a0rows.\")", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "The CSV file has 45212\u00a0rows.\n"}], "execution_count": 3}, {"id": "6a8cf2e5-f669-492f-b338-743b5f6ca8fc", "cell_type": "code", "source": "import csv\n\ndef count_rows(file_path):\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        row_count = sum(1 for row in reader)\n    return row_count\n\n# Specify the path to your CSV file\ncsv_file_path = 'bank.csv'\n\n# Count the number of rows in the CSV file\nnum_rows = count_rows(csv_file_path)\n\nprint(f\"The CSV file has {num_rows}\u00a0rows.\")", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "The CSV file has 4522\u00a0rows.\n"}], "execution_count": 4}, {"id": "f8daad2a-4e39-4e8f-a7ad-1056aac35730", "cell_type": "markdown", "source": "## Data Type & Understanding\n*Column Descriptions*\n\n- age (Integer): Age of the customer\n- job (String): Type of job.\n- marital (String): Marital status.\n- education (String): Education level.\n- default (Boolean): Has credit in default?\n- balance (Integer): Account balance.\n- housing (Boolean): Has housing loan?\n- loan (Boolean): Has personal loan?\n- contact (String): Contact communication type.\n- day (Integer): Last contact day of the month.\n- month (String): Last contact month of the year.\n- duration (Integer): Last contact duration (in seconds).\n- campaign (Integer): Number of contacts called during this campaign for this client.\n- pdays (Integer): Number of days that passed after the client was last contacted from a previous campaign.\n- previous (Integer): Number of contacts called before this campaign for this client.\n- poutcome (Integer): Outcome of the previous marketing campaign.\n- y (Boolean): Has the client subscribed to a term deposit?", "metadata": {}}, {"id": "bb210a08-724b-402f-8137-fd467769ae24", "cell_type": "markdown", "source": "## Data Types for Analysis", "metadata": {}}, {"id": "38014e57-0bfe-43cb-b574-a160e74be386", "cell_type": "code", "source": "import pandas as pd\nimport csv\nfrom typing import Dict\nfrom pprint import pprint\n\ndef analyze_csv(file_path: str) -> Dict[str, str]:\n    # Read the CSV file\n    df = pd.read_csv(file_path, sep=\";\")\n    d = {}\n    for column in df.columns:\n        dtype = str(df[column].dtype)\n        if dtype not in d:\n            d[dtype] = []\n        d[dtype].append(column)\n    return d\n\npprint(analyze_csv(\"bank.csv\"))", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{'int64': ['age',\n           'balance',\n           'day',\n           'duration',\n           'campaign',\n           'pdays',\n           'previous'],\n 'object': ['job',\n            'marital',\n            'education',\n            'default',\n            'housing',\n            'loan',\n            'contact',\n            'month',\n            'poutcome',\n            'y']}\n"}], "execution_count": 11}, {"id": "469dcbf1-8ee7-4ad6-a52c-90ed0865f8af", "cell_type": "markdown", "source": "## What are possible problems in the data?", "metadata": {}}, {"id": "4bd4fff0-2f93-47f2-9ad0-9d321a8bc629", "cell_type": "markdown", "source": "### 1) Booleans are represented as yes/no strings\n\n**Solution**: To overcome this problem, when reading the file- \nneed to add logic to parse the yes/no into boolean true or false. \n\n### 2) Null values are represented by the string 'unknown'\n**Solution**: Possible solution, use the mean of each column or look at other similar data to predict to a estimated value for the column- (Technique: K nearest neighbors)- if time permits we can implement this technique.\n\n### 3) Unknown values in pdays seem to be represented by -1- we don't know what this means?\n**Solution**: We need more information to understand what this represents to consider it in the model.", "metadata": {}}, {"id": "9cb4abc6-074d-4760-b434-80fd3949f28a", "cell_type": "markdown", "source": "## Checking for outliers and skewness", "metadata": {}}, {"id": "1d636404-2a66-4918-aec4-fe679dd103ef", "cell_type": "markdown", "source": "### 1) data is semicolon-delimited, not comma-delimited", "metadata": {}}, {"id": "9c0b0071-2b4d-40e1-ac8d-505ee1d54c37", "cell_type": "markdown", "source": "#### Solution: the argument `sep=\";\"` must be passed in each call to pd.read_csv()", "metadata": {}}, {"id": "4ec285cd-d56e-460b-bc42-e10a7f3c9346", "cell_type": "markdown", "source": "#### 2) The distribution of labels is skewed heavily to one side, the model may be biased toward that result", "metadata": {}}, {"id": "e8d3095a-985f-4e81-bfa1-a2d799dc3294", "cell_type": "code", "source": "import pandas as pd\n\n# Read the CSV file\ndf = pd.read_csv('bank-full.csv',sep=\";\")\n\n# Count the values in the last column\nvalue_counts = df.iloc[:, -1].value_counts()\n\n# Print the results\nprint(\"Value counts in the last column:\")\nprint(value_counts)\n\n# Calculate percentages\ntotal = value_counts.sum()\npercentages = (value_counts / total) * 100\n\nprint(\"\\nPercentages:\")\nfor value, count in value_counts.items():\n    percentage = percentages[value]\n    print(f\"{value}: {count} ({percentage:.2f}%)\")", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}, {"id": "c7b97ed5-68c7-4d63-a4d9-394fbd13c95d", "cell_type": "markdown", "source": "#### Solution: pre-process the test and training data to remove \"no\" rows (i.e. take a random sample) until the output distribution is about 50% yes and 50% no", "metadata": {}}, {"id": "c8f8d0e5-7bd8-4153-9908-38ce56ea115e", "cell_type": "code", "source": "import pandas as pd\n\ndef balance_csv(input_file, output_file, sample_size=None):\n    # Read the CSV file\n    df = pd.read_csv(input_file, sep=';')\n    \n    # Get the target column (last column)\n    target_col = df.columns[-1]\n    \n    # Group by the target column\n    grouped = df.groupby(target_col)\n    \n    # Determine the sample size for each group\n    if sample_size is None:\n        sample_size = grouped.size().min()\n    else:\n        sample_size = min(sample_size // 2, grouped.size().min())\n    \n    # Take a random sample from each group\n    sampled = grouped.apply(lambda x: x.sample(n=sample_size, random_state=42))\n    \n    # Reset the index\n    df_balanced = sampled.reset_index(drop=True)\n    \n    # Shuffle the DataFrame to mix 'yes' and 'no' rows\n    df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n    \n    # Write to output file\n    df_balanced.to_csv(output_file, sep=';', index=False)\n    \n    # Print statistics\n    value_counts = df_balanced[target_col].value_counts()\n    print(f\"Output file created: {output_file}\")\n    print(f\"Yes count: {value_counts.get('yes', 0)}\")\n    print(f\"No count: {value_counts.get('no', 0)}\")\n\n# Usage\nbalance_csv('bank.csv', 'bank_balanced.csv')\nbalance_csv('bank-full.csv', 'bank-full_balanced.csv')", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Output file created: bank_balanced.csv\nYes count: 521\nNo count: 521\nOutput file created: bank-full_balanced.csv\nYes count: 5289\nNo count: 5289\n"}], "execution_count": 19}, {"id": "872a54d5-7f8b-4286-9d92-57bf548aea77", "cell_type": "markdown", "source": "#### 3) There are a significant number of outliers in the numerical columns\n### Outlier- is a data point that has a significantly different value than majority of the values in the dataset.", "metadata": {}}, {"id": "d5fbd727-c3e1-46e5-8a7c-d85251dee960", "cell_type": "code", "source": "import pandas as pd\nimport numpy as np\n\ndef check_outliers(file_path, delimiter=';'):\n    df = pd.read_csv(file_path, delimiter=delimiter)\n\n    def find_outliers(series):\n        Q1 = series.quantile(0.25)\n        Q3 = series.quantile(0.75)\n        IQR = Q3 - Q1\n        lower_bound = Q1 - 1.5 * IQR\n        upper_bound = Q3 + 1.5 * IQR\n        return series[(series < lower_bound) | (series > upper_bound)]\n\n    for column in df.select_dtypes(include=[np.number]).columns:\n        outliers = find_outliers(df[column])\n        if not outliers.empty:\n            print(f\"\\nOutliers in column '{column}':\")\n            print(f\"Number of outliers: {len(outliers)}\")\n            print(f\"Percentage of outliers: {(len(outliers) / len(df[column])) * 100:.2f}%\")\n\ncheck_outliers('bank-full.csv')", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "\nOutliers in column 'age':\nNumber of outliers: 487\nPercentage of outliers: 1.08%\n\nOutliers in column 'balance':\nNumber of outliers: 4729\nPercentage of outliers: 10.46%\n\nOutliers in column 'duration':\nNumber of outliers: 3235\nPercentage of outliers: 7.16%\n\nOutliers in column 'campaign':\nNumber of outliers: 3064\nPercentage of outliers: 6.78%\n\nOutliers in column 'pdays':\nNumber of outliers: 8257\nPercentage of outliers: 18.26%\n\nOutliers in column 'previous':\nNumber of outliers: 8257\nPercentage of outliers: 18.26%\n"}], "execution_count": 27}, {"id": "e48401f5-477d-4530-9f2b-d613e951b070", "cell_type": "markdown", "source": "#### Solution: For most numerica columns we impute the mean. For pdays and previous we ignore values that encode false.", "metadata": {}}, {"id": "c37cb1de-69dc-4216-a17b-9c337f73306b", "cell_type": "code", "source": "import pandas as pd\nimport numpy as np\n\nfile_path = \"bank-full.csv\"\n\ndef impute_outliers(df):\n    for column in [\"balance\",\"campaign\", \"duration\", \"pdays\", \"previous\"]:\n        if column == \"pdays\":\n            valid_data = df[df[column] != -1][column]\n        elif column == \"previous\":\n            valid_data = df[df[column] != 0][column]\n        else:\n            valid_data = df[column]\n        \n        mean = valid_data.mean()\n        std = valid_data.std()\n        lower_limit = mean - std\n        upper_limit = mean + std\n\n        # Only impute values that are not -1 for pdays or 0 for previous\n        if column == \"pdays\":\n            df.loc[(df[column] < lower_limit) & (df[column] != -1), column] = mean\n            df.loc[(df[column] > upper_limit) & (df[column] != -1), column] = mean\n        elif column == \"previous\":\n            df.loc[(df[column] < lower_limit) & (df[column] != 0), column] = mean\n            df.loc[(df[column] > upper_limit) & (df[column] != 0), column] = mean\n        else:\n            df.loc[df[column] < lower_limit, column] = mean\n            df.loc[df[column] > upper_limit, column] = mean\n\n    return df\n\n# Impute outliers\ndf = pd.read_csv('bank.csv', sep=';')\ndf_imputed = impute_outliers(df)\n\ndef check_outliers(df):\n    def find_outliers(series, ignore_value=None):\n        if ignore_value is not None:\n            series = series[series != ignore_value]\n        Q1 = series.quantile(0.25)\n        Q3 = series.quantile(0.75)\n        IQR = Q3 - Q1\n        lower_bound = Q1 - 1.5 * IQR\n        upper_bound = Q3 + 1.5 * IQR\n        return series[(series < lower_bound) | (series > upper_bound)]\n\n    for column in df.select_dtypes(include=[np.number]).columns:\n        if column == \"pdays\":\n            outliers = find_outliers(df[column], ignore_value=-1)\n        elif column == \"previous\":\n            outliers = find_outliers(df[column], ignore_value=0)\n        else:\n            outliers = find_outliers(df[column])\n        \n        print(f\"\\nOutliers in column '{column}':\")\n        print(f\"Number of outliers: {len(outliers)}\")\n        print(f\"Percentage of outliers: {(len(outliers) / len(df[column])) * 100:.2f}%\")\n\ndf = pd.read_csv('bank.csv', sep=';')\ncheck_outliers(df)\nprint('-------------------------')\ncheck_outliers(df_imputed)\n", "metadata": {"scrolled": true, "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "\nOutliers in column 'age':\nNumber of outliers: 38\nPercentage of outliers: 0.84%\n\nOutliers in column 'balance':\nNumber of outliers: 506\nPercentage of outliers: 11.19%\n\nOutliers in column 'day':\nNumber of outliers: 0\nPercentage of outliers: 0.00%\n\nOutliers in column 'duration':\nNumber of outliers: 330\nPercentage of outliers: 7.30%\n\nOutliers in column 'campaign':\nNumber of outliers: 318\nPercentage of outliers: 7.03%\n\nOutliers in column 'pdays':\nNumber of outliers: 7\nPercentage of outliers: 0.15%\n\nOutliers in column 'previous':\nNumber of outliers: 34\nPercentage of outliers: 0.75%\n-------------------------\n\nOutliers in column 'age':\nNumber of outliers: 38\nPercentage of outliers: 0.84%\n\nOutliers in column 'balance':\nNumber of outliers: 156\nPercentage of outliers: 3.45%\n\nOutliers in column 'day':\nNumber of outliers: 0\nPercentage of outliers: 0.00%\n\nOutliers in column 'duration':\nNumber of outliers: 34\nPercentage of outliers: 0.75%\n\nOutliers in column 'campaign':\nNumber of outliers: 0\nPercentage of outliers: 0.00%\n\nOutliers in column 'pdays':\nNumber of outliers: 119\nPercentage of outliers: 2.63%\n\nOutliers in column 'previous':\nNumber of outliers: 0\nPercentage of outliers: 0.00%\n"}, {"name": "stderr", "output_type": "stream", "text": "/tmp/ipykernel_124/3939564569.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '1422.6578190665782' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n  df.loc[df[column] < lower_limit, column] = mean\n/tmp/ipykernel_124/3939564569.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2.793629727936297' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n  df.loc[df[column] < lower_limit, column] = mean\n/tmp/ipykernel_124/3939564569.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '263.96129174961294' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n  df.loc[df[column] < lower_limit, column] = mean\n/tmp/ipykernel_124/3939564569.py:22: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '224.86519607843138' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n  df.loc[(df[column] < lower_limit) & (df[column] != -1), column] = mean\n/tmp/ipykernel_124/3939564569.py:25: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '3.0061274509803924' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n  df.loc[(df[column] < lower_limit) & (df[column] != 0), column] = mean\n"}], "execution_count": 4}, {"id": "146d07ef-1f2d-45fd-8ef3-b044676fe451", "cell_type": "markdown", "source": "#### 4) Identifying the skewness in the features", "metadata": {}}, {"id": "e75b99b4-2541-448e-9aa5-87f119a0144f", "cell_type": "code", "source": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import skew\n\ndef check_skewness(df, printing=True):\n    highly_skewed_columns = []\n    def interpret_skewness(sk):\n        if sk < -1:\n            return \"Highly Negatively Skewed\"\n        elif -1 <= sk < -0.5:\n            return \"Moderately Negatively Skewed\"\n        elif -0.5 <= sk < 0:\n            return \"Approximately Symmetric (Slightly Negative)\"\n        elif sk == 0:\n            return \"Perfectly Symmetric\"\n        elif 0 < sk < 0.5:\n            return \"Approximately Symmetric (Slightly Positive)\"\n        elif 0.5 <= sk < 1:\n            return \"Moderately Positively Skewed\"\n        else:\n            return \"Highly Positively Skewed\"\n\n    # Check each numeric column for skewness\n    for column in df.select_dtypes(include=[np.number]).columns:\n        sk = skew(df[column].dropna())\n        interpretation = interpret_skewness(sk)\n        if printing:\n            print(f\"\\nColumn: {column}\")\n            print(f\"Skewness: {sk:.4f}\")\n            print(f\"Interpretation: {interpretation}\")\n        if abs(sk) > 1:\n            highly_skewed_columns.append(column)\n\n    return highly_skewed_columns\n\n# Usage\ndf = pd.read_csv('bank.csv', delimiter=';')\ncheck_skewness(df)\n    ", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "\nColumn: age\nSkewness: 0.6993\nInterpretation: Moderately Positively Skewed\n\nColumn: balance\nSkewness: 6.5942\nInterpretation: Highly Positively Skewed\n\nColumn: day\nSkewness: 0.0946\nInterpretation: Approximately Symmetric (Slightly Positive)\n\nColumn: duration\nSkewness: 2.7715\nInterpretation: Highly Positively Skewed\n\nColumn: campaign\nSkewness: 4.7423\nInterpretation: Highly Positively Skewed\n\nColumn: pdays\nSkewness: 2.7162\nInterpretation: Highly Positively Skewed\n\nColumn: previous\nSkewness: 5.8733\nInterpretation: Highly Positively Skewed\n"}, {"data": {"text/plain": "['balance', 'duration', 'campaign', 'pdays', 'previous']"}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "execution_count": 5}, {"id": "459f583e-6e95-4a46-8fa5-dec1d2aee4dd", "cell_type": "markdown", "source": "#### Solution: Apply a log transformation- replacing values. It would preserve information and reduce space in values. \r\nCreating a log transformation to replace values. This action would preserve the information in the data set.\r\n", "metadata": {}}, {"id": "e7f0f80e-bdbe-4615-b10d-6df9fcf8d57a", "cell_type": "code", "source": "import pandas as pd\nimport numpy as np\n\ndef apply_log_transformations(df, log_columns):\n    df_transformed = df.copy()\n    \n    for col in log_columns:\n        if col in df_transformed.columns:\n            min_value = df_transformed[col].min()\n            if min_value <= 0:\n                df_transformed[col] = df_transformed[col] - min_value + 1\n            df_transformed[col] = np.log1p(df_transformed[col])\n            #df_transformed.rename(columns={col: f'{col}_log'}, inplace=True)\n\n    return df_transformed\ndf = pd.read_csv('bank.csv', delimiter=';')\nlog_columns = check_skewness(df, printing=False)\nprev_len = 0\nwhile len(log_columns) != prev_len:\n    prev_len = len(log_columns)\n    df = apply_log_transformations(df, check_skewness(df, printing=False))\n    log_columns = check_skewness(df, printing=False)\ncheck_skewness(df)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "\nColumn: age\nSkewness: 0.6993\nInterpretation: Moderately Positively Skewed\n\nColumn: balance\nSkewness: 0.1212\nInterpretation: Approximately Symmetric (Slightly Positive)\n\nColumn: day\nSkewness: 0.0946\nInterpretation: Approximately Symmetric (Slightly Positive)\n\nColumn: duration\nSkewness: -0.4677\nInterpretation: Approximately Symmetric (Slightly Negative)\n\nColumn: campaign\nSkewness: 0.7649\nInterpretation: Moderately Positively Skewed\n\nColumn: pdays\nSkewness: 1.6881\nInterpretation: Highly Positively Skewed\n\nColumn: previous\nSkewness: 2.2485\nInterpretation: Highly Positively Skewed\n"}, {"data": {"text/plain": "['pdays', 'previous']"}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "execution_count": 6}, {"id": "674bce3c-9ebf-4219-b5ae-8192d4e914c2", "cell_type": "markdown", "source": "## Data Processing", "metadata": {}}, {"id": "82197d94-8005-4919-902b-e5ab04c072d4", "cell_type": "markdown", "source": "*Data Cleaning Steps*\n- Handling missing values.\n- Converting categorical variables to numeric formats (if needed).\n- Checking for and handling any outliers.", "metadata": {}}, {"id": "99355201-673a-424c-8f28-f4e92b526205", "cell_type": "markdown", "source": "*Handling Missing Values*:\n- Checking for missing values in each column.\n- Filling or dropping missing values as appropriate.\n- Encoding Categorical Variables:\n- Converting categorical variables into numeric using one-hot encoding or label encoding.\n- Handling Outliers:\n- Identifying and handling any outliers in the dataset.", "metadata": {}}, {"id": "c4b8ad7f-bdf3-41e4-8c9e-2f6f66cf5c0c", "cell_type": "markdown", "source": "## Checking for missing values", "metadata": {}}, {"id": "53a76e0f-2e2e-4b4b-8f12-5953c9f61e5c", "cell_type": "code", "source": "## Checking for missing values\nimport pandas as pd\ndf = pd.read_csv('bank.csv', sep=';')\nmissing_values = df.isnull().any(axis=1).sum() #it will check inside the columns of the dataframes\n\nprint (missing_values)\n", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "0\n"}], "execution_count": 5}, {"id": "e254339c-2570-4686-b9b2-e0a0bee3ec7f", "cell_type": "markdown", "source": "### Solution: There is no null values", "metadata": {}}, {"id": "8cece625-8dd4-487f-9259-83f95c7b9156", "cell_type": "markdown", "source": "## 5 Questions that can lead to actionable recommendations and solutions (Use for EDA Report)\n\n1) Which demographic factors  are most strongly associated with the likelihood of subscribing to the term deposit?\n\n2) How do the different channels of communication (cell phone vs. telephone landline) affect the success rate of term deposit subscriptions?\n\n3) What is the impact of economic indicators (employment variation rate, consumer price index, euribor 3 month rate) on customer subscription rates?\n\n4) How does the timing of the last contact (month and day of the week) influence the likelihood of a positive response?\n\n5) What role do past campaign outcomes (previous contact and poutcome) play in predicting the success of the current campaign?", "metadata": {}}, {"id": "dff8934d-bfae-4aef-a904-78ebbcebc126", "cell_type": "markdown", "source": "## EDA With Charts & Explanations\n\nChart for each question and hypothesis", "metadata": {}}, {"id": "1677b81c-0a7f-496c-b42b-7f9d9030b6f5", "cell_type": "markdown", "source": "## 5 Hypotheses that can lead to actionable recommendations and solutions (Use to Generate Model)\n\n## Hypothesis 1: \n\u25aa\ufe0e Customers between the ages of 30-40 years old are more likely to subscribe to a term deposit than others.\n\n## Hypothesis 2: \n\u25aa\ufe0e The success rate of term deposit subscriptions is higher when using cell phone communication compared to regular landline telephone communication.\n\n## Hypothesis 3: \n\u25aa\ufe0e Positive economic indicators such as: higher employment variation rate, lower consumer price index, are associated with higher subscription rates for term deposits.\n\n## Hypothesis 4: \n\u25aa\ufe0e Contacts made during specific days of the week have a higher success rate for term deposit subscriptions.\n\n## Hypothesis 5: \n\u25aa\ufe0e Customers with previous successful campaign outcomes are more likely to subscribe to a term deposit in the current campaign.", "metadata": {"jp-MarkdownHeadingCollapsed": true}}, {"id": "50580413-6f50-4d25-a77f-667f0cd4f60c", "cell_type": "code", "source": "## Importing Libraries", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}, {"id": "f7565b80-854c-41a4-8f83-43280b582a11", "cell_type": "code", "source": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.utils import resample\n\n# Assuming `data_encoded` is already defined from the previous steps\n\n# Re-defining train-test split\nX = data_encoded.drop(columns=['y'])\ny = data_encoded['y'].apply(lambda x: 1 if x == 'yes' else 0)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n# Concatenate our training data back together\ntrain_data = pd.concat([X_train, y_train], axis=1)\n\n# Separate minority and majority classes\nno_subscribe = train_dat\n", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}, {"id": "88c8958a-1171-43e5-9225-874691be3324", "cell_type": "markdown", "source": "## Model Building", "metadata": {}}, {"id": "901c8f1b-c68e-4690-8eab-6d79fc7dfdcd", "cell_type": "markdown", "source": "## Model Selection", "metadata": {}}, {"id": "a442838a-f97b-4973-a131-f569b68245e2", "cell_type": "markdown", "source": "## Performance Deploying", "metadata": {}}, {"id": "99595f30-4526-410c-8bed-89ee87d7a35a", "cell_type": "markdown", "source": "## Deploy the Model", "metadata": {}}, {"id": "739b36a0-f248-4143-99f9-0c82e4e5d2aa", "cell_type": "markdown", "source": "## Convert ML Metrics to Business Metrics ", "metadata": {}}, {"id": "a838f0b6-4233-4bee-9b07-2c162151b7a0", "cell_type": "markdown", "source": "## Explanation of Results to Business", "metadata": {"jp-MarkdownHeadingCollapsed": true}}, {"id": "75b1aa1a-3872-49e4-b554-5af8902d570c", "cell_type": "markdown", "source": "## The End. Thanks for viewing our presentation.", "metadata": {}}]}